{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In this notebook, we are creating metadata to ingest NBA clips"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List all the files uploaded to NBA folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Copyright (c) Microsoft Corporation.\n",
    "Licensed under the MIT license.\n",
    "\"\"\"\n",
    "from enrichment.metadata_parser.metadata_parser import MetadataParser\n",
    "from azure.storage.blob import BlobServiceClient\n",
    "from datetime import datetime\n",
    "\n",
    "# setting up variables for connection and source to the source storage acount/container\n",
    "source_account_key = ''\n",
    "account_name = 'nbavideofootage'\n",
    "container = 'videos'\n",
    "source_connection_string = f'DefaultEndpointsProtocol=https;AccountName={account_name};AccountKey={source_account_key};EndpointSuffix=core.windows.net'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_service = BlobServiceClient.from_connection_string(conn_str=source_connection_string)\n",
    "source_container_client = source_service.get_container_client(container)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nba_file_names = [x['name'] for x in source_container_client.list_blobs( name_starts_with='footage')]\n",
    "len(nba_file_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize DataFrame to fill in the information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(nba_file_names)\n",
    "df.columns = ['matching_video_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import random\n",
    "\n",
    "# fake creation dates to avoid going to Youtube API\n",
    "def random_date(start, end):\n",
    "    \"\"\"Generate a random datetime between `start` and `end`\"\"\"\n",
    "    return start + datetime.timedelta(\n",
    "        # Get a random amount of seconds between `start` and `end`\n",
    "        seconds=random.randint(0, int((end - start).total_seconds())),\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define content for NBA metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['video_description'] = df['matching_video_name'].apply(lambda x: x.split('ENT')[0].replace('_',' '))\n",
    "df['usage_terms'] = 'No Restrictions'\n",
    "df['video_languages'] = \"English\"\n",
    "df['video_languages_code'] = 'en-US'\n",
    "df['keywords'] = [['Sport','Basketball','NBA'] for i in df.index] \n",
    "df['version'] = 1\n",
    "df['first_creation_date'] = df['version'].apply(lambda x: random_date(pd.to_datetime('2020-01-01'),pd.to_datetime('2022-07-20')))\n",
    "df['current_version_creation_date'] = df['first_creation_date'].astype(str)\n",
    "df['first_creation_date'] = df['first_creation_date'].astype(str)\n",
    "df['file_name'] = df['matching_video_name'].apply(lambda x: x.split('.')[0])\n",
    "df['data_source'] = 'nba'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_jsons  = df.to_dict('records')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert DataFrame into a list of dictionaries and save those as JSON files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "for json_file in list_of_jsons:\n",
    "\n",
    "    parser = MetadataParser()\n",
    "    parsed = parser.parse_metadata(json_file)\n",
    "    \n",
    "    # Move the video file to a new location\n",
    "    video_blob  =  source_container_client.get_blob_client(parsed['matching_video_name'])\n",
    "    target_video_blob =  source_container_client.get_blob_client(f\"{parsed['file_name']}/{parsed['matching_video_name']}\") \n",
    "    target_video_blob.start_copy_from_url(video_blob.url)\n",
    "    # Upload the Json to a blob in the same directory\n",
    "    new_blob_name = f\"{parsed['file_name']}/{parsed['file_name']}.json\"\n",
    "    blob_client = source_container_client.get_blob_client(new_blob_name)\n",
    "    try:\n",
    "        blob_client.upload_blob(json.dumps(parsed), overwrite=True)\n",
    "    except:\n",
    "        continue\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0c6cc133ec6a912106c5bc979cd972ec7614f3fd6f379383284e0bb5f07e3cc2"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
