{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Insights Combiner\n",
    "\n",
    "#### When searching for an interesting insight, we want to be able to combine all our enrichments into a single document\n",
    "#### In this notebook we will go over the steps to combine the various insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Copyright (c) Microsoft Corporation.\n",
    "Licensed under the MIT license.\n",
    "\"\"\"\n",
    "from azure.storage.blob import BlobServiceClient\n",
    "from enrichment.metadata_parser.json_reader import json_reader\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "storage_account_name = 'datastoragestg9ki9'\n",
    "# key can be grabbed from https://portal.azure.com/#@waldosearch.onmicrosoft.com/resource/subscriptions/26ca8759-8cc8-49b7-9d4e-5ade3345bc0d/resourceGroups/rg-waldo-stg-9ki9-core/providers/Microsoft.Storage/storageAccounts/datastoragestg9ki9/keys\n",
    "account_storage_key = '' #insert storage key\n",
    "container_name = 'upload'\n",
    "\n",
    "storage_meta = dict()\n",
    "storage_meta['account_name'] = storage_account_name\n",
    "storage_meta['account_storage_key'] = account_storage_key\n",
    "storage_meta['container_name'] = container_name\n",
    "\n",
    "# connect to storage container\n",
    "connection_string = f\"DefaultEndpointsProtocol=https;AccountName={storage_account_name};AccountKey={account_storage_key};EndpointSuffix=core.windows.net\"\n",
    "service = BlobServiceClient.from_connection_string(conn_str=connection_string)\n",
    "container_client = service.get_container_client(container_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all files and storage and filter json files\n",
    "all_files = list(container_client.list_blobs(name_starts_with = 'msr-vtt'))\n",
    "json_files = list(filter(lambda file: file['name'].endswith('json'),all_files))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read and parse a JSON file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the JSON file\n",
    "%store -r data\n",
    "file_to_read = 'msr-vtt/video1001/video1001.json'\n",
    "data = json_reader(container_client, file_to_read)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from enrichment.metadata_parser.metadata_parser import MetadataParser\n",
    "parser  = MetadataParser()\n",
    "parsed_data = parser.parse_metadata(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read and parse Video Indexer insights for that file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from enrichment.vi_insights_parser.vi_insights_parser import ViInsightsParser\n",
    "\n",
    "vi_insights_file = 'common/notebooks/demo/insights_combiner/vi_insights.json'\n",
    "vi_parser = ViInsightsParser()\n",
    "insights = vi_parser.load_vi_insights(vi_insights_file)\n",
    "parsed_vi_insights = vi_parser.parse_vi_insights(insights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extract NER for this file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from enrichment.entity_extractor.entity_extractor import EntityExtractor, EntityTypeConfig\n",
    "import enrichment.entity_extractor.utils as entity_extractor_utils\n",
    "\n",
    "# Let's build and initialize the EntityExtractor object. \n",
    "ner_extractor = EntityExtractor()\n",
    "endpoint='https://eastus.api.cognitive.microsoft.com/'\n",
    "# key can be grabbed from: https://portal.azure.com/#@waldosearch.onmicrosoft.com/resource/subscriptions/26ca8759-8cc8-49b7-9d4e-5ade3345bc0d/resourceGroups/rg-waldo-stg-9ki9-ml/providers/Microsoft.CognitiveServices/accounts/textanalytics-stg-9ki9/cskeys\n",
    "key = '' # Insert key\n",
    "ner_extractor.initialize_client(endpoint, key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each type of named entity needs to be configured separately.\n",
    "\n",
    "# For locations, we will be using a threshold of 0.9 as the minimum confidence for a named entity to be considered,\n",
    "# the elements in the video_locations field of the xml will be added unconditionally to the set of locations.\n",
    "# and elements that are substrings of others will be removed (e.g., \"Zurich\" and \"Zurich, Switzerland\" --> only \"Zurich, Switzerland\" will be left)\n",
    "locations_ner_config = EntityTypeConfig('Location', \n",
    "                                        threshold=0.9, \n",
    "                                        add_from_xml=['video_locations'],\n",
    "                                        remove_substrings=True)\n",
    "\n",
    "# For people, we will also use a threshold of 0.85,\n",
    "# and remove elements that are substrings of others (e.g., remove the family name if we already have the given and family names)\n",
    "people_ner_config = EntityTypeConfig('Person',\n",
    "                                    threshold=0.85,\n",
    "                                    remove_substrings=True)\n",
    "\n",
    "# For organizations, we do similarly than we did for people, but adding the field 'company_names' inconditionally.\n",
    "organizations_ner_config = EntityTypeConfig('Organization',\n",
    "                                           threshold=0.85,\n",
    "                                           add_from_xml=['company_names'],\n",
    "                                           remove_substrings=True)\n",
    "\n",
    "ner_extractor.initialize_entity_type_configs([locations_ner_config, people_ner_config, organizations_ner_config])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_insights = ner_extractor.extract_entities(parsed_data)\n",
    "ner_insights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now let's combine all insights into the final document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from enrichment.insights_combiner.insights_combiner import InsightsCombiner\n",
    "combiner = InsightsCombiner()\n",
    "final_doc = combiner.combine_insights(vi_insights=parsed_vi_insights,\n",
    "                                        metadata = parsed_data,\n",
    "                                        ner_insights = ner_insights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "949777d72b0d2535278d3dc13498b2535136f6dfe0678499012e853ee9abcab1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
