{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Split VI Insights into Segments"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Video Indexer generates multiple AI based insights on uploaded videos.<br>\n",
                "A small sample of these insights include -\n",
                "* Audio transcript\n",
                "* Textual charachters which appear in video frames using OCR\n",
                "* Topic detection\n",
                "One intereting insight that VI produces is a segmentation of the video into scenes and shots, which allow a more granular view of the video\n",
                "\n",
                "The VI generates a long JSON file which includes the summarization of all these insights.\n",
                "By indexing the JSON file in Azure Cognitive search, we can search these insights and find **videos** containing any of the identified insights.\n",
                "\n",
                "### Why split VI insights into smaller segments?\n",
                "Azure simple search retrieves documents based on BM25 which is based on Term Frequency.\n",
                "Using the full JSON as a single document for BM25 evaluation may dilute important information we want to search.\n",
                "By splitting the VI insights into smaller interval based files, will allow to identify areas of interest and pinpoint to specific times in the video.\n",
                "\n",
                "### How does the Splitter work?\n",
                "The `VIinsightsToSegmentsParser` iterates over the various insights which are generated by the Video Indexer and splits the file into segments based on the following logic.\n",
                "1. _scenes_ - The insights in the JSON file are split based on the `scenes` key in the insights.\n",
                "2. _shots_ - The insights in the JSON file are split based on the `shots` key in the insights. Each scene may be split into multiple shots. A new shot represents a change in the angle of the camera.\n",
                "3. _intervals_ - equal sized segments, split by n seconds. For example a video with duration 100 seconds and 30 second interval, will be split into 4 segments.\n",
                "\n",
                "### How does assignment work?\n",
                "A particular insights may span over multiple segments. For example a car may appear in a video for 30 seconds, but the scene ends at 00:00:25 seconds, meaning the car appears in multiple scenes. How do we split the insgiths into segments in this case?\n",
                "The `overlap` parameter will define how the assignment works\n",
                "1. _first_ - Will assign an insight into the **first** relevant segment. Meaning that each insight instance will appear only in 1 segment.\n",
                "2. _duplicate_ - Will assign the insights into **every** segment relevant to the instance\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Load VI Insights File (will be read from the API)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [],
            "source": [
                "\"\"\"\n",
                "Copyright (c) Microsoft Corporation.\n",
                "Licensed under the MIT license.\n",
                "\"\"\"\n",
                "import json\n",
                "\n",
                "def read_json_file(location):\n",
                "    # Opening JSON file\n",
                "    f = open(location, \"r\")\n",
                "    # returns JSON object as a dictionary\n",
                "    data = json.load(f)\n",
                "    return data\n",
                "\n",
                "data = read_json_file('common/notebooks/demo/insights_splitter/insights/exmp2.json')\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Load the Parser"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "dict_keys(['INSIGHTS_STATIC_FIELDS', 'SUMMARIZED_INSIGHTS_TO_KEEP', 'INSIGHTS_TO_PARSE', 'DEFAULT_OVERLAP', 'DEFAULT_INTERVAL_DURATION'])\n"
                    ]
                }
            ],
            "source": [
                "from enrichment.insights_splitter.insights_to_segments_splitter import VIinsightsToSegmentsParser\n",
                "configuration = read_json_file(\"common/enrichment/insights_splitter/splitter_configuration.jsonc\")\n",
                "print(configuration.keys())\n",
                "parser = VIinsightsToSegmentsParser(configuration)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Let's Parse the insights into **equal** length intervals"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "interval_segments = parser.split_vi_insights(data,\n",
                "                                            segment_type = 'interval',\n",
                "                                            interval_duration = 5,\n",
                "                                            keys_to_extract=['transcript','ocr'],\n",
                "                                            overlap = 'first'\n",
                "                                            )\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### Look at the generated segment keys"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "interval_segments.keys()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### Now we can look at segment starting at 10<X<=15 seconds and look at all the transcripts generated at that interval.\n",
                "You can see that the second instance starts at time 00:00:14 and lasts until 00:00:21 (spanning over multiple segments)<br>\n",
                "We won't find this transcript in any additional segments\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "interval_segments[10]['videos'][0]['insights']['transcript']"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Let's parse the inisghts based on VI **scenes**\n",
                "The example we're running includes 6 scenes, so we expect to have 6 generated segments"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "len(data['videos'][0]['insights']['scenes'])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "scene_segments = parser.split_vi_insights(data,\n",
                "                                            segment_type = 'scenes',\n",
                "                                            keys_to_extract=['transcript','ocr'],\n",
                "                                            overlap = 'first'\n",
                "                                            )"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "scene_segments.keys()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### Let's look at transcript starting at second 69"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "scene_segments[69]['videos'][0]['insights']['transcript'][0]"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Let's Look at **duplicate** overlap methodology "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [],
            "source": [
                "shots_segments = parser.split_vi_insights(data,\n",
                "                                        segment_type = 'shots',\n",
                "                                        keys_to_extract=['labels'],\n",
                "                                        overlap = 'duplicate'\n",
                "                                        )"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "In the original insights, there is a _man_ label appearing in several timestamps.\n",
                "The man appears from 01:15(75 seconds) - 01:25 (85 seconds)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "{'confidence': 0.9764,\n",
                            " 'adjustedStart': '0:01:15.075',\n",
                            " 'adjustedEnd': '0:01:25.1183666',\n",
                            " 'start': '0:01:15.075',\n",
                            " 'end': '0:01:25.1183666'}"
                        ]
                    },
                    "execution_count": 12,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "[x for x in data['videos'][0]['insights']['labels'] if x['name']=='man'][0]['instances'][1]\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "This insights is spanning across 2 segments; segment 69 & 85,\n",
                "so we expect to see this insight duplicated across those segments\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 15,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "odict_keys([0.0, 5.0, 15.0, 53.0, 65.0, 69.0, 85.0, 94.0, 100.0, 113.0, 124.0])"
                        ]
                    },
                    "execution_count": 15,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "shots_segments.keys()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 37,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "{'confidence': 0.9764,\n",
                            " 'adjustedStart': '0:01:15.075',\n",
                            " 'adjustedEnd': '0:01:25.1183666',\n",
                            " 'start': '0:01:15.075',\n",
                            " 'end': '0:01:25.1183666'}"
                        ]
                    },
                    "execution_count": 37,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "shots_segments[85]['videos'][0]['insights']['labels'][3]['instances'][1]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 35,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "{'confidence': 0.9764,\n",
                            " 'adjustedStart': '0:01:15.075',\n",
                            " 'adjustedEnd': '0:01:25.1183666',\n",
                            " 'start': '0:01:15.075',\n",
                            " 'end': '0:01:25.1183666'}"
                        ]
                    },
                    "execution_count": 35,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "shots_segments[69]['videos'][0]['insights']['labels'][7]['instances'][1]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        }
    ],
    "metadata": {
        "interpreter": {
            "hash": "0c6cc133ec6a912106c5bc979cd972ec7614f3fd6f379383284e0bb5f07e3cc2"
        },
        "kernelspec": {
            "display_name": "Python 3.9.10 ('base')",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.9.12"
        },
        "orig_nbformat": 4
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
