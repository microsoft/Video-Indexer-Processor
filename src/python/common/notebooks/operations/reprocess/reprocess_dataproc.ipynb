{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Copyright (c) Microsoft Corporation.\n",
    "Licensed under the MIT license.\n",
    "\"\"\"\n",
    "#!pip install -r  operations/reprocess/requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "import time\n",
    "import os\n",
    "from tqdm import tqdm \n",
    "from dotenv import load_dotenv\n",
    "from azure.cosmos import CosmosClient\n",
    "from azure.storage.blob import BlobServiceClient\n",
    "from azure.servicebus import ServiceBusClient, ServiceBusMessage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reprocess insights\n",
    "\n",
    "This notebook can be used to re-process insights. It will take all the insights from Cosmos DB, retrieve their original JSON data file from storage, and send that file to the data processing queue.\n",
    "\n",
    "This will re-run the `func_dataproc` pipeline, which merges the insights and then writes the results to Cosmos DB.\n",
    "\n",
    "**Note:** this notebooks requires the Cosmos DB and Service Bus SDKs. See `requirements.txt`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cosmos DB (in Keys -> Primary connection String)\n",
    "file_with_secrets = \"python/.env\"\n",
    "load_dotenv(file_with_secrets)\n",
    "\n",
    "# Cosmos DB (in Keys -> Primary connection String)\n",
    "STG_COSMOS_ENDPOINT =  os.getenv(\"STG_COSMOS_ENDPOINT\") \n",
    "STG_COSMOS_KEY = os.getenv(\"STG_COSMOS_KEY\") \n",
    "STG_COSMOS_NAME = os.getenv(\"STG_COSMOS_NAME\")\n",
    "STG_CONTAINER =  os.getenv(\"STG_CONTAINER\")\n",
    "\n",
    "# Storage (connection string is in Access Keys -> Connection String)\n",
    "BLOB_UPLOAD_STORAGE_KEY = os.getenv(\"BLOB_UPLOAD_STORAGE_KEY\") \n",
    "BLOB_CONNECTION_STRING = os.getenv(\"BLOB_CONNECTION_STRING\") \n",
    "BLOB_STORAGE_ACCOUNT_NAME = os.getenv(\"BLOB_STORAGE_ACCOUNT_NAME\")\n",
    "BLOB_CONTAINER_NAME = os.getenv(\"BLOB_CONTAINER_NAME\") \n",
    "\n",
    "# Service Bus (take from Shared Access Policies -> RootManageSharedAccessKey -> Primary Connection String)\n",
    "SERVICEBUS_KEY = os.getenv(\"SERVICEBUS_KEY\")\n",
    "SERVICEBUS_RESOURCE_NAME = os.getenv(\"SERVICEBUS_RESOURCE_NAME\")\n",
    "SERVICEBUS_CONNECTION_STRING = os.getenv(\"SERVICEBUS_CONNECTION_STRING\") \n",
    "SERVICEBUS_QUEUE = os.getenv(\"SERVICEBUS_QUEUE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trigger Processing Including Reparsing JSON Metadata\n",
    "\n",
    "By adding metadata to the blob, the last update date is changed and the trigger orchestrator is triggered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list all JSON files in folder\n",
    "blob_service_client = BlobServiceClient.from_connection_string(BLOB_CONNECTION_STRING)\n",
    "container_client = blob_service_client.get_container_client(BLOB_CONTAINER_NAME)\n",
    "# folder in the container to take files from\n",
    "folder_base = 'msr-vtt/'\n",
    "all_json_files = list(container_client.list_blobs(name_starts_with = folder_base))\n",
    "all_json_files = [i for i in all_json_files if i['name'].endswith('.json')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4023/4023 [06:12<00:00, 10.81it/s]\n"
     ]
    }
   ],
   "source": [
    "# add metadata to each blob in folder\n",
    "for blob in tqdm(all_json_files):\n",
    "    blob_client = container_client.get_blob_client(blob['name'])\n",
    "    blob_client.set_blob_metadata({'manually_triggered': '08-15-2022'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trigger Processing **WITHOUT** Reparsing JSON Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read all items from Cosmos DB\n",
    "\n",
    "cosmos_client = CosmosClient(STG_COSMOS_ENDPOINT, STG_COSMOS_KEY)\n",
    "database = cosmos_client.get_database_client(STG_COSMOS_NAME)\n",
    "cosmos_container = database.get_container_client(STG_CONTAINER)\n",
    "cosmos_items = list(cosmos_container.read_all_items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each item, read the parsed JSON from silver storage\n",
    "# And use it to send the JSON messages to the dataproc queue\n",
    "\n",
    "blob_service_client = BlobServiceClient.from_connection_string(BLOB_CONNECTION_STRING)\n",
    "container_client = blob_service_client.get_container_client(BLOB_CONTAINER_NAME)\n",
    "\n",
    "servicebus_client = ServiceBusClient.from_connection_string(conn_str = SERVICEBUS_CONNECTION_STRING, logging_enable=True)\n",
    "sender = servicebus_client.get_queue_sender(queue_name=SERVICEBUS_QUEUE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_latest_metadata(blobs):\n",
    "    \"\"\"Find the latest version of metadata file in a list of blobs.\"\"\"\n",
    "    latest_blob = {}\n",
    "    latest_version = 0\n",
    "\n",
    "    for blob in blobs:\n",
    "        match = blob['name'].endswith('.json')\n",
    "\n",
    "        if match:\n",
    "            blob_client = container_client.get_blob_client(blob['name'])\n",
    "            metadata = blob_client.download_blob().readall()\n",
    "            metadata_dict = json.loads(metadata)\n",
    "            \n",
    "            version = metadata_dict['version']\n",
    "        \n",
    "            if version > latest_version:\n",
    "                latest_version = version\n",
    "                latest_blob = metadata_dict\n",
    "\n",
    "    return latest_blob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3945/3945 [18:42<00:00,  3.51it/s]\n"
     ]
    }
   ],
   "source": [
    "folder_base = 'msr-vtt/'\n",
    "\n",
    "for i in tqdm(cosmos_items):\n",
    "    id = i['id']\n",
    "    desc = i['description']\n",
    "\n",
    "    if '/' in desc:\n",
    "        desc = desc.split('/')[1]\n",
    "    # This below is necessary due to the naming conventions in the sample folder(to be modified if necessary) \n",
    "    folder = desc.split('.')[0].split('_')[0]\n",
    "    folder = folder_base + folder + \"/\"\n",
    "\n",
    "    # List all blobs and find and load the latest JSON Metadata\n",
    "    blobs = container_client.list_blobs(name_starts_with = folder)\n",
    "    metadata_dict = find_latest_metadata(blobs)\n",
    "\n",
    "    # Add video_id to the message\n",
    "    metadata_dict['video_id'] = id\n",
    "\n",
    "    # Post the message to queue\n",
    "    payload = json.dumps(metadata_dict)\n",
    "\n",
    "    message = ServiceBusMessage(payload)\n",
    "    sender.send_messages(message)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "c10a2a6bb51805b3f2c7da176b506728fcd4842ded6c1f89423002188fd8bedf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
